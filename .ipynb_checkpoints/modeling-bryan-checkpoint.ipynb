{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "In this file, instructions how to approach the challenge can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work on different types of Machine Learning problems:\n",
    "\n",
    "- **Regression Problem**: The goal is to predict delay of flights.\n",
    "- **(Stretch) Multiclass Classification**: If the plane was delayed, we will predict what type of delay it is (will be).\n",
    "- **(Stretch) Binary Classification**: The goal is to predict if the flight will be cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, roc_auc_score, roc_curve, auc\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as holiday_calendar\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Task: Regression Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **ARR_DELAY**. We need to be careful which columns to use and which don't. For example, DEP_DELAY is going to be the perfect predictor, but we can't use it because in real-life scenario, we want to predict the delay before the flight takes of --> We can use average delay from earlier days but not the one from the actual flight we predict.  \n",
    "\n",
    "For example, variables **CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY** shouldn't be used directly as predictors as well. However, we can create various transformations from earlier values.\n",
    "\n",
    "We will be evaluating your models by predicting the ARR_DELAY for all flights **1 week in advance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('flights_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fl_date', 'mkt_unique_carrier', 'branded_code_share', 'mkt_carrier',\n",
       "       'mkt_carrier_fl_num', 'op_unique_carrier', 'tail_num',\n",
       "       'op_carrier_fl_num', 'origin_airport_id', 'origin', 'origin_city_name',\n",
       "       'dest_airport_id', 'dest', 'dest_city_name', 'crs_dep_time',\n",
       "       'crs_arr_time', 'dup', 'crs_elapsed_time', 'flights', 'distance',\n",
       "       'arr_delay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['mkt_unique_carrier', 'branded_code_share', 'origin_city_name', 'dest_city_name', 'origin_airport_id', 'dest_airport_id',\n",
    "        'op_unique_carrier', 'tail_num', 'op_carrier_fl_num', 'dup', 'flights'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>mkt_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>crs_arr_time</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>arr_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>131</td>\n",
       "      <td>MCO</td>\n",
       "      <td>LAX</td>\n",
       "      <td>1837</td>\n",
       "      <td>2130</td>\n",
       "      <td>353</td>\n",
       "      <td>2218</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>132</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MCO</td>\n",
       "      <td>2220</td>\n",
       "      <td>605</td>\n",
       "      <td>285</td>\n",
       "      <td>2218</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>135</td>\n",
       "      <td>JFK</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1920</td>\n",
       "      <td>2309</td>\n",
       "      <td>349</td>\n",
       "      <td>2153</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>136</td>\n",
       "      <td>PHX</td>\n",
       "      <td>JFK</td>\n",
       "      <td>2248</td>\n",
       "      <td>520</td>\n",
       "      <td>272</td>\n",
       "      <td>2153</td>\n",
       "      <td>-12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>144</td>\n",
       "      <td>CHS</td>\n",
       "      <td>DCA</td>\n",
       "      <td>635</td>\n",
       "      <td>758</td>\n",
       "      <td>83</td>\n",
       "      <td>444</td>\n",
       "      <td>-22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fl_date mkt_carrier  mkt_carrier_fl_num origin dest  crs_dep_time  \\\n",
       "0  2018-01-01          B6                 131    MCO  LAX          1837   \n",
       "1  2018-01-01          B6                 132    LAX  MCO          2220   \n",
       "2  2018-01-01          B6                 135    JFK  PHX          1920   \n",
       "3  2018-01-01          B6                 136    PHX  JFK          2248   \n",
       "4  2018-01-01          B6                 144    CHS  DCA           635   \n",
       "\n",
       "   crs_arr_time  crs_elapsed_time  distance  arr_delay  \n",
       "0          2130               353      2218       42.0  \n",
       "1           605               285      2218       27.0  \n",
       "2          2309               349      2153        1.0  \n",
       "3           520               272      2153      -12.0  \n",
       "4           758                83       444      -22.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering will play a crucial role in this problems. We have only very little attributes so we need to create some features that will have some predictive power.\n",
    "\n",
    "- weather: we can use some weather API to look for the weather in time of the scheduled departure and scheduled arrival.\n",
    "- statistics (avg, mean, median, std, min, max...): we can take a look at previous delays and compute descriptive statistics\n",
    "- airports encoding: we need to think about what to do with the airports and other categorical variables\n",
    "- time of the day: the delay probably depends on the airport traffic which varies during the day.\n",
    "- airport traffic\n",
    "- unsupervised learning as feature engineering?\n",
    "- **what are the additional options?**: Think about what we could do more to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the month, and the hour of the flight\n",
    "# from datetime import datetime\n",
    "# X['fl_date'] = X['fl_date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "# X['month'] = X['fl_date'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hour(x):\n",
    "    x = str(int(x))\n",
    "    if len(x) == 4:\n",
    "        return int(x[:2])\n",
    "    return int(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['d_hour'] = X['crs_dep_time'].apply(lambda x: get_hour(x))\n",
    "X['a_hour'] = X['crs_arr_time'].apply(lambda x: get_hour(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['crs_arr_time', 'crs_dep_time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>mkt_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>d_hour</th>\n",
       "      <th>a_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>131</td>\n",
       "      <td>MCO</td>\n",
       "      <td>LAX</td>\n",
       "      <td>353</td>\n",
       "      <td>2218</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>132</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MCO</td>\n",
       "      <td>285</td>\n",
       "      <td>2218</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>135</td>\n",
       "      <td>JFK</td>\n",
       "      <td>PHX</td>\n",
       "      <td>349</td>\n",
       "      <td>2153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>136</td>\n",
       "      <td>PHX</td>\n",
       "      <td>JFK</td>\n",
       "      <td>272</td>\n",
       "      <td>2153</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>144</td>\n",
       "      <td>CHS</td>\n",
       "      <td>DCA</td>\n",
       "      <td>83</td>\n",
       "      <td>444</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fl_date mkt_carrier  mkt_carrier_fl_num origin dest  crs_elapsed_time  \\\n",
       "0  2018-01-01          B6                 131    MCO  LAX               353   \n",
       "1  2018-01-01          B6                 132    LAX  MCO               285   \n",
       "2  2018-01-01          B6                 135    JFK  PHX               349   \n",
       "3  2018-01-01          B6                 136    PHX  JFK               272   \n",
       "4  2018-01-01          B6                 144    CHS  DCA                83   \n",
       "\n",
       "   distance  arr_delay  d_hour  a_hour  \n",
       "0      2218       42.0      18      21  \n",
       "1      2218       27.0      22       6  \n",
       "2      2153        1.0      19      23  \n",
       "3      2153      -12.0      22       5  \n",
       "4       444      -22.0       6       7  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fl_date               0\n",
       "mkt_carrier           0\n",
       "mkt_carrier_fl_num    0\n",
       "origin                0\n",
       "dest                  0\n",
       "crs_elapsed_time      0\n",
       "distance              0\n",
       "arr_delay             0\n",
       "d_hour                0\n",
       "a_hour                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dummy variables\n",
    "# X = pd.get_dummies(X, columns=['mkt_carrier'])\n",
    "X = pd.get_dummies(X, prefix=['M', 'D', 'A'], columns=['mkt_carrier', 'd_hour', 'a_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fl_date', 'mkt_carrier_fl_num', 'origin', 'dest', 'crs_elapsed_time',\n",
       "       'distance', 'arr_delay', 'M_AA', 'M_AS', 'M_B6', 'M_DL', 'M_F9', 'M_G4',\n",
       "       'M_HA', 'M_NK', 'M_UA', 'M_VX', 'M_WN', 'D_1', 'D_2', 'D_3', 'D_4',\n",
       "       'D_5', 'D_6', 'D_7', 'D_8', 'D_9', 'D_10', 'D_11', 'D_12', 'D_13',\n",
       "       'D_14', 'D_15', 'D_16', 'D_17', 'D_18', 'D_19', 'D_20', 'D_21', 'D_22',\n",
       "       'D_23', 'A_1', 'A_2', 'A_3', 'A_4', 'A_5', 'A_6', 'A_7', 'A_8', 'A_9',\n",
       "       'A_10', 'A_11', 'A_12', 'A_13', 'A_14', 'A_15', 'A_16', 'A_17', 'A_18',\n",
       "       'A_19', 'A_20', 'A_21', 'A_22', 'A_23', 'A_24'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection / Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to apply different selection techniques to find out which one will be the best for our problems.\n",
    "\n",
    "- Original Features vs. PCA conponents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X.sample(n=5000)\n",
    "y = X_sample['arr_delay']\n",
    "X_sample.drop(['arr_delay'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sample.drop(['fl_date', 'mkt_carrier_fl_num', 'origin', 'dest'], axis=1), y, test_size=0.3, random_state=42)\n",
    "# X_train.drop(['fl_date', 'mkt_carrier_fl_num', 'origin', 'dest'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use different ML techniques to predict each problem.\n",
    "\n",
    "- linear / logistic / multinomial logistic regression\n",
    "- Naive Bayes\n",
    "- Random Forest\n",
    "- SVM\n",
    "- XGBoost\n",
    "- The ensemble of your own choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try random forest regression with default settings as a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate random forest ensemble for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv = RandomizedSearchCV(estimator=RandomForestRegressor(), param_distributions=random_grid, n_iter = 50, cv = 3, verbose=2, random_state=42, n_jobs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=50,\n",
       "                   n_jobs=12,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1600,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -26.983 (1.212)\n"
     ]
    }
   ],
   "source": [
    "# n_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=12, error_score='raise')\n",
    "# # report performance\n",
    "# print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features='sqrt', max_depth=10, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=10, max_features='sqrt', min_samples_leaf=4,\n",
       "                      n_estimators=1600)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = X['arr_delay']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(['fl_date', 'mkt_carrier_fl_num', 'origin', 'dest', 'arr_delay'], axis=1), y, test_size=0.3, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015464830432012633"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('randomforest_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.2461, 'distance'), (0.2401, 'crs_elapsed_time'), (0.0363, 'D_6'), (0.0349, 'M_UA'), (0.0306, 'M_DL'), (0.0288, 'M_B6'), (0.0267, 'D_7'), (0.0215, 'D_2'), (0.0213, 'D_17'), (0.0185, 'A_21'), (0.0182, 'M_F9'), (0.0176, 'A_8'), (0.0172, 'D_19'), (0.0144, 'A_20'), (0.0138, 'M_AS'), (0.0124, 'A_18'), (0.0123, 'M_AA'), (0.0122, 'D_20'), (0.0111, 'D_8'), (0.0092, 'A_5'), (0.0092, 'A_22'), (0.0088, 'D_18'), (0.0088, 'A_19'), (0.0084, 'D_5'), (0.0077, 'D_15'), (0.0075, 'A_9'), (0.0071, 'A_7'), (0.007, 'M_WN'), (0.0069, 'A_11'), (0.0062, 'A_10'), (0.0059, 'A_6'), (0.0053, 'D_9'), (0.0052, 'A_23'), (0.0048, 'D_16'), (0.0044, 'A_13'), (0.0042, 'D_14'), (0.0041, 'D_23'), (0.004, 'D_21'), (0.0038, 'D_13'), (0.0038, 'D_12'), (0.0035, 'A_12'), (0.0034, 'D_11'), (0.0031, 'A_17'), (0.003, 'D_10'), (0.003, 'A_16'), (0.0027, 'A_15'), (0.0026, 'M_NK'), (0.0022, 'A_14'), (0.0022, 'A_1'), (0.0019, 'M_HA'), (0.0017, 'D_22'), (0.0014, 'M_G4'), (0.0014, 'A_3'), (0.0007, 'A_4'), (0.0005, 'A_2'), (0.0003, 'D_3'), (0.0001, 'D_1'), (0.0, 'M_VX'), (0.0, 'D_4'), (0.0, 'A_24')]\n"
     ]
    }
   ],
   "source": [
    "print (\"Features sorted by their score:\")\n",
    "names = X_train.columns\n",
    "print (sorted(zip(map(lambda x: round(x, 4), model.feature_importances_), names), \n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have data from 2018 and 2019 to develop models. Use different evaluation metrics for each problem and compare the performance of different models.\n",
    "\n",
    "You are required to predict delays on **out of sample** data from **first 7 days (1st-7th) of January 2020** and to share the file with LighthouseLabs. Sample submission can be found in the file **_sample_submission.csv_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================\n",
    "## Stretch Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variables are **CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY**. We need to do additional transformations because these variables are not binary but continuos. For each flight that was delayed, we need to have one of these variables as 1 and others 0.\n",
    "\n",
    "It can happen that we have two types of delays with more than 0 minutes. In this case, take the bigger one as 1 and others as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **CANCELLED**. The main problem here is going to be huge class imbalance. We have only very little cancelled flights with comparison to all flights. It is important to do the right sampling before training and to choose correct evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
